{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnTt09jy2cAv"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "from google.colab import drive\n",
        "import hashlib\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def loadParagraphs(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        paragraphs = file.readlines()\n",
        "\n",
        "    return [p.strip() for p in paragraphs if p.strip()]\n",
        "\n",
        "def kShingles(paragraph, k):\n",
        "    words = paragraph.split()\n",
        "    shingles = set()\n",
        "    for i in range(len(words) - k + 1):\n",
        "        shingle = ' '.join(words[i:i + k])\n",
        "        shingles.add(shingle)\n",
        "    return shingles\n",
        "\n",
        "def hashShingles(shingles):\n",
        "    return {\n",
        "        int(hashlib.sha256(shingle.encode()).hexdigest(), 16) % 10000 for shingle in shingles\n",
        "        }\n",
        "\n",
        "\n",
        "def minhashSignatures(sortedPairs, n):\n",
        "    signatures = {\n",
        "        doc_id: [float('inf')] * n for doc_id in sortedPairs.keys()\n",
        "        }\n",
        "    for i in range(n):\n",
        "        randomHash = random.sample(range(1, 10001), len(sortedPairs))\n",
        "        for doc_id, shingle_list in sortedPairs.items():\n",
        "            for shingle in shingle_list:\n",
        "                if signatures[doc_id][i]>randomHash[shingle % len(randomHash)]:\n",
        "                    signatures[doc_id][i]=randomHash[shingle % len(randomHash)]\n",
        "    return signatures\n",
        "\n",
        "def candidatePairs(signatures, b, r):\n",
        "    buckets = defaultdict(list)\n",
        "    for doc_id, signature in signatures.items():\n",
        "        for i in range(b):\n",
        "            band = tuple(signature[i * r:(i + 1) * r])\n",
        "            buckets[band].append(doc_id)\n",
        "    return buckets\n",
        "\n",
        "def jaccardSimilarity(shinglesA, shinglesB):\n",
        "    intersection = len(shinglesA.intersection(shinglesB))\n",
        "    union = len(shinglesA.union(shinglesB))\n",
        "    return intersection / union if union != 0 else 0\n",
        "\n",
        "file_path = \"/content/drive/My Drive/Datasets/Project2_dataset_similarity.txt\"\n",
        "paragraphs = loadParagraphs(file_path)\n",
        "\n",
        "k = 5\n",
        "\n",
        "shingleDict = {i: kShingles(paragraph, k) for i, paragraph in enumerate(paragraphs)}\n",
        "hashedShingles = {i: hashShingles(shingles) for i, shingles in shingleDict.items()}\n",
        "\n",
        "n = 100\n",
        "b = 3\n",
        "r = 10\n",
        "\n",
        "signatures = minhashSignatures(hashedShingles, n)\n",
        "candidates = candidatePairs(signatures, b, r)\n",
        "\n",
        "similarPairs = []\n",
        "threshold = 0.92\n",
        "for bucket in candidates.values():\n",
        "    if len(bucket) > 1:\n",
        "\n",
        "        for i in range(len(bucket)):\n",
        "            for j in range(i + 1, len(bucket)):\n",
        "                shinglesA = shingleDict[bucket[i]]\n",
        "                shinglesB = shingleDict[bucket[j]]\n",
        "\n",
        "                similar = jaccardSimilarity(shinglesA, shinglesB)\n",
        "                if similar >= threshold:\n",
        "                    similarPairs.append((bucket[i], bucket[j], similar))\n",
        "\n",
        "for doc1, doc2, similar in similarPairs:\n",
        "    print(f\"Paragraphs {doc1} and {doc2} are similar with similarity {similar:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\n",
        "Chose shingle size k = 5 to avoid common 2 or 3 word phrases. It represents a good trade-off between generating a lot of shingles if a smaller k was used while also generating enough to detect patterns among similar paragraphs.\n",
        "\n",
        "2.\n",
        "Naive comparison of Minhash signatures is extremely inefficient requiring a quadratic number of comparisons. The Banding Technique and LSH improves efficiency by focusing only on likely similar document pairs, filtering out pairs that are not likely to be similar.\n",
        "\n",
        "3.\n",
        "My analysis identified a large number of paragraph pairs that have identical similarity scores. For certain pairs they are indeed identical (119, 247) but I am not sure they are completely identical for every identified pair. Minhash signatures of certain paragraphs could be the same, but the actual paragraphs may not actually be identical."
      ],
      "metadata": {
        "id": "8Dz6J9jD2nsW"
      }
    }
  ]
}